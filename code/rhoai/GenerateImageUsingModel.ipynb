{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09c673d",
   "metadata": {},
   "source": [
    "# Generating image using the fine-tuned StableDiffusion XL model with DreamBooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aac13c",
   "metadata": {},
   "source": [
    "This notebook uses a deployed StableDiffusion XL model, which has already been fine-tuned using DreamBooth, to generate toy-jensen image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee02dd",
   "metadata": {},
   "source": [
    "### Call the model infernece endpoint\n",
    "\n",
    "To generate the image using the deployed model, we will need to invoke the deployed model's inference endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33488fe1",
   "metadata": {},
   "source": [
    "# Imports needed to perform the REST call and show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44322953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff19a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the inference endpoint\n",
    "inference_endpoint = '<MODEL_INFERENCE_ENDPOINT>'\n",
    "\n",
    "# Change the name of the model (from \"nvidia\") if a different model_name is specified in the ServingRuntime\n",
    "predict_endpoint = inference_endpoint + '/v1/models/nvidia:predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the request data for fetching the image\n",
    "data = {\n",
    "  \"instances\": [\n",
    "    {\n",
    "      \"prompt\": \"A picture of toy jensen in space\",\n",
    "      \"num_inference_steps\": 75\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Send a request to your server\n",
    "response = requests.post(predict_endpoint, json=data, verify=False)\n",
    "\n",
    "# Get the Base64-encoded image string from the response\n",
    "img_str = response.json()[\"predictions\"][0][\"image\"][\"b64\"]\n",
    "\n",
    "# Decode the Base64 string to bytes\n",
    "img_bytes = base64.b64decode(img_str)\n",
    "\n",
    "# Convert bytes data to PIL Image\n",
    "img = Image.open(BytesIO(img_bytes))\n",
    "\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
